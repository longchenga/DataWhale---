{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBOS学习\n",
    "\n",
    "[因为昨天重装了系统 所以我的conda环境有了点问题 代码类实现出现困难 后期修补后会再改进的~]\n",
    "HBOS全名为：Histogram-based Outlier Score。它是⼀种单变量⽅法的组合，不能对特征之间的依赖关系进⾏建模，但是计算速度较快，对⼤数据集友好。其基本假设是数据集的每个维度相互独⽴。然后对每个维度进⾏区间(bin)划分，区间的密度越⾼，异常评分越低。\n",
    "\n",
    "**一、HBOS背景**\n",
    "在网络安全领域，对异常检测算法的效率要求很高，且输入数据往往非常大，这也是为什么半监督学习的异常检测算法往往采用直方图的原因。如果处理的是高维数据，单维度的直方图很容易计算。大多数直方图相关的算法中，常常固定直方图的宽度或者手动设置宽度。论文提出了一种基于直方图的无监督异常检测算法，并且提出了动态宽度的算法以适应不均衡的长尾分布。\n",
    "论文来源：Histogram-based Outlier Score (HBOS): A fast Unsupervised Anomaly Detection Algorithm\n",
    "\n",
    "**二、HBOS简介**\n",
    "HBOS算法基于多维数据各个维度的独立性假设，对于单个数据维度，先做出数据直方图。对于categroy 值，统计每个值出现的次数，并计算相对频率。对于数值特征，可以用两种方法：\n",
    "    【1】静态跨度的柱状图：将值域分成K个等宽的桶，落入每个桶的值的频数作为密度的估计（桶的高度）\n",
    "    【2】动态宽度柱状图：先将所有值排序，然后将连续的N/k个值装进一个桶里，其中N是所有的样例数，k是桶的个数，是一个超参数；柱状图的面积对应桶中的样例数。因为桶的宽度是有桶中第一个值和最后一个值决定的，所有桶的面积都一样，所以，每一个桶的高度可以被计算出来。这意味着跨度大的桶的高度低，即密度小，只有一种情况例外，超过k个数相等，此时一个桶里允许超过N/k个值。\n",
    "\n",
    "**三、HBOS算法流程：**\n",
    "1.为每个数据维度做出数据直⽅图。\n",
    "2.对每个维度都计算了⼀个独⽴的直⽅图，其中每个箱⼦的⾼度表示密度的估计。\n",
    "检测异常方法：HBOS分值越高，样本越异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program\\Anaconda\\Lib\\site-packages\\pyod\\utils\\data.py:189: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.8.0. Please use behaviour=\"new\", which makes the returned datasets in the order of X_train, X_test, y_train, y_test.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On Training Data:\n",
      "HBOS ROC:0.9947, precision @ rank n:0.8\n",
      "\n",
      "On Test Data:\n",
      "HBOS ROC:0.9744, precision @ rank n:0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Example of using Histogram- based outlier detection (HBOS) for\n",
    "outlier detection\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    contamination = 0.1  # percentage of outliers\n",
    "    n_train = 200  # number of training points\n",
    "    n_test = 100  # number of testing points\n",
    "\n",
    "    # Generate sample data\n",
    "    X_train, y_train, X_test, y_test = \\\n",
    "        generate_data(n_train=n_train,\n",
    "                      n_test=n_test,\n",
    "                      n_features=2,\n",
    "                      contamination=contamination,\n",
    "                      random_state=42)\n",
    "\n",
    "    # train HBOS detector\n",
    "    clf_name = 'HBOS'\n",
    "    clf = HBOS()\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    # get the prediction labels and outlier scores of the training data\n",
    "    y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "    # get the prediction on the test data\n",
    "    y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
    "\n",
    "    # evaluate and print the results\n",
    "    print(\"\\nOn Training Data:\")\n",
    "    evaluate_print(clf_name, y_train, y_train_scores)\n",
    "    print(\"\\nOn Test Data:\")\n",
    "    evaluate_print(clf_name, y_test, y_test_scores)\n",
    "\n",
    "    # visualize the results\n",
    "    visualize(clf_name, X_train, y_train, X_test, y_test, y_train_pred,\n",
    "              y_test_pred, show_figure=True, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有关于HBOS类的学习\n",
    "\n",
    "参数：\n",
    "n_bins、alpha、tol、contamination。默认：n_bins=10, alpha=0.1, tol=0.5, contamination=0.\n",
    "\n",
    "输入：\n",
    "训练数据\n",
    "\n",
    "函数：\n",
    "fit训练函数/decision_function精度评定函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HBOS(BaseDetector):\n",
    "    \"\"\"Histogram- based outlier detection (HBOS) is an efficient unsupervised\n",
    "    method. It assumes the feature independence and calculates the degree\n",
    "    of outlyingness by building histograms. See :cite:`goldstein2012histogram`\n",
    "    for details.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_bins : int, optional (default=10)\n",
    "        The number of bins.\n",
    "\n",
    "    alpha : float in (0, 1), optional (default=0.1)\n",
    "        The regularizer for preventing overflow.\n",
    "\n",
    "    tol : float in (0, 1), optional (default=0.5)\n",
    "        The parameter to decide the flexibility while dealing\n",
    "        the samples falling outside the bins.\n",
    "\n",
    "    contamination : float in (0., 0.5), optional (default=0.1)\n",
    "        The amount of contamination of the data set,\n",
    "        i.e. the proportion of outliers in the data set. Used when fitting to\n",
    "        define the threshold on the decision function.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    bin_edges_ : numpy array of shape (n_bins + 1, n_features )\n",
    "        The edges of the bins.\n",
    "\n",
    "    hist_ : numpy array of shape (n_bins, n_features)\n",
    "        The density of each histogram.\n",
    "\n",
    "    decision_scores_ : numpy array of shape (n_samples,)\n",
    "        The outlier scores of the training data.\n",
    "        The higher, the more abnormal. Outliers tend to have higher\n",
    "        scores. This value is available once the detector is fitted.\n",
    "\n",
    "    threshold_ : float\n",
    "        The threshold is based on ``contamination``. It is the\n",
    "        ``n_samples * contamination`` most abnormal samples in\n",
    "        ``decision_scores_``. The threshold is calculated for generating\n",
    "        binary outlier labels.\n",
    "\n",
    "    labels_ : int, either 0 or 1\n",
    "        The binary labels of the training data. 0 stands for inliers\n",
    "        and 1 for outliers/anomalies. It is generated by applying\n",
    "        ``threshold_`` on ``decision_scores_``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_bins=10, alpha=0.1, tol=0.5, contamination=0.1):\n",
    "        super(HBOS, self).__init__(contamination=contamination)\n",
    "        self.n_bins = n_bins\n",
    "        self.alpha = alpha\n",
    "        self.tol = tol\n",
    "\n",
    "        check_parameter(alpha, 0, 1, param_name='alpha')\n",
    "        check_parameter(tol, 0, 1, param_name='tol')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit detector. y is ignored in unsupervised methods.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        y : Ignored\n",
    "            Not used, present for API consistency by convention.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted estimator.\n",
    "        \"\"\"\n",
    "        # validate inputs X and y (optional)\n",
    "        X = check_array(X)\n",
    "        self._set_n_classes(y)\n",
    "\n",
    "        n_samples, n_features = X.shape[0], X.shape[1]\n",
    "        self.hist_ = np.zeros([self.n_bins, n_features])\n",
    "        self.bin_edges_ = np.zeros([self.n_bins + 1, n_features])\n",
    "\n",
    "        # build the histograms for all dimensions\n",
    "        for i in range(n_features):\n",
    "            self.hist_[:, i], self.bin_edges_[:, i] = \\\n",
    "                np.histogram(X[:, i], bins=self.n_bins, density=True)\n",
    "            # the sum of (width * height) should equal to 1\n",
    "            assert (np.isclose(1, np.sum(\n",
    "                self.hist_[:, i] * np.diff(self.bin_edges_[:, i])), atol=0.1))\n",
    "\n",
    "        # outlier_scores = self._calculate_outlier_scores(X)\n",
    "        outlier_scores = _calculate_outlier_scores(X, self.bin_edges_,\n",
    "                                                   self.hist_,\n",
    "                                                   self.n_bins,\n",
    "                                                   self.alpha, self.tol)\n",
    "\n",
    "        # invert decision_scores_. Outliers comes with higher outlier scores\n",
    "        self.decision_scores_ = invert_order(np.sum(outlier_scores, axis=1))\n",
    "        self._process_decision_scores()\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Predict raw anomaly score of X using the fitted detector.\n",
    "\n",
    "        The anomaly score of an input sample is computed based on different\n",
    "        detector algorithms. For consistency, outliers are assigned with\n",
    "        larger anomaly scores.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            The training input samples. Sparse matrices are accepted only\n",
    "            if they are supported by the base estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        anomaly_scores : numpy array of shape (n_samples,)\n",
    "            The anomaly score of the input samples.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, ['hist_', 'bin_edges_'])\n",
    "        X = check_array(X)\n",
    "\n",
    "        # outlier_scores = self._calculate_outlier_scores(X)\n",
    "        outlier_scores = _calculate_outlier_scores(X, self.bin_edges_,\n",
    "                                                   self.hist_,\n",
    "                                                   self.n_bins,\n",
    "                                                   self.alpha, self.tol)\n",
    "        return invert_order(np.sum(outlier_scores, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBOS代码的复现-基于网页代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'fsspec'.  Use pip or conda to install fsspec.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bf68715dd19f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhbos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHBOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D://Sample - Superstore.xls\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program\\Anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 )\n\u001b[0;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mD:\\program\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workbook_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_filepath_or_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workbook_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"s3n://\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"s3n://\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s3://\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mfsspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fsspec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# If botocore is installed we fallback to reading with anon=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program\\Anaconda\\Lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'fsspec'.  Use pip or conda to install fsspec."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "df = pd.read_excel(\"D://Sample - Superstore.xls\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
